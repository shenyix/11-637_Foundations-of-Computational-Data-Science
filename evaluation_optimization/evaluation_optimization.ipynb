{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 7: Evaluation Optimization\n",
    "\n",
    "In this project, we will develop a question-answering system. Please note that **usage of the `Standard_NC6` GPU compute on Azure ML Studio is required, starting from Question 2**.\n",
    "\n",
    "## Some words of caution\n",
    "Based on past semesters, this has been the most difficult project in the course. You will be working with computationally heavy models, and the local test for each question may take from 3-10 minutes to run. In addition, Question 8 (Fine-tuning BERT) will take two hours to run. Given these challenges, we have tried to be as thorough as possible in the question descriptions. Please read them carefully --  **spending 5 minutes to double check the instructions can sometimes save you hours of debugging**. In addition, plan your implementation carefully before writing any code, and always start testing on small subsets of the data.\n",
    "\n",
    "For long-running tasks, a great way to track your code's progress is through the `tqdm` library (see the [TQDM primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/tqdm-primer/tqdm_primer.ipynb) for more details), which we have imported below. Whenever you use Pandas' `.apply` or `.map` method, replace them with `.progress_apply` and `.progress_map` to see the progress bar.\n",
    "\n",
    "Also make sure to monitor your Azure budget carefully; you will not be able to finish this project and the final exam if you run out of budget. Note that **your remaining budget is in the Education tab on Azure, not the Cost Monitoring tab**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, json, pickle, ast, time, random, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "import ssl\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "nltk.download(\"stopwords\", quiet = True)\n",
    "nltk.download(\"wordnet\", quiet = True)\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet = True)\n",
    "nltk.download(\"punkt\", quiet = True)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GLOBAL_SEED = 1\n",
    " \n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "GLOBAL_WORKER_ID = None\n",
    "def _init_fn(worker_id):\n",
    "    global GLOBAL_WORKER_ID\n",
    "    GLOBAL_WORKER_ID = worker_id\n",
    "    set_seed(GLOBAL_SEED + worker_id)\n",
    "\n",
    "set_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(actual, expected):\n",
    "    assert actual == expected, actual\n",
    "\n",
    "def check_approx(actual, expected):\n",
    "    assert np.allclose(actual, expected), actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Project Overview\n",
    "We will train our NLP models on the [Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/), a reading comprehension dataset with more than 100,000 questions. SQuAD was one of the first with a public leaderboard and thus was able to garner a large amount of research result and publicity towards itself. Questions in the dataset can be answered from the context that accompanies them, without requiring any domain-specific knowledge; thus they belong to the class of *single-hop* question answering problem.\n",
    "\n",
    "Here's an example of what our model will do: given a *question*,\n",
    "```\n",
    "When did Beyonce start becoming popular?\n",
    "```\n",
    "and a block of text containing the answer, called the *context*,\n",
    "```\n",
    "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
    "```\n",
    "our model will be able to extract the answer from this context, which is `in the late 1990s`.\n",
    "\n",
    "We will start by evaluating some simple models that only identify the sentence that contains the answer (i.e., the *answer sentence*) within the context. Then we'll move to a state-of-the-art model called BERT that can also identify the exact answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the dataset -- note that the following cell should have the tag `excluded_from_script`, since the autograder will use a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context_paragraph</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "      <th>context_sentences</th>\n",
       "      <th>answer_sent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "      <td>Managed by her father, Mathew Knowles, the gro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "0           When did Beyonce start becoming popular?   \n",
       "0           When did Beyonce start becoming popular?   \n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "4         In which decade did Beyonce become famous?   \n",
       "4         In which decade did Beyonce become famous?   \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                   context_paragraph               answer  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "\n",
       "   answer_start  answer_end  \\\n",
       "0           269         286   \n",
       "0           269         286   \n",
       "0           269         286   \n",
       "0           269         286   \n",
       "1           207         226   \n",
       "1           207         226   \n",
       "1           207         226   \n",
       "1           207         226   \n",
       "2           526         530   \n",
       "2           526         530   \n",
       "2           526         530   \n",
       "2           526         530   \n",
       "3           166         180   \n",
       "3           166         180   \n",
       "3           166         180   \n",
       "3           166         180   \n",
       "4           276         286   \n",
       "4           276         286   \n",
       "4           276         286   \n",
       "4           276         286   \n",
       "\n",
       "                                   context_sentences  answer_sent_index  \n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  1  \n",
       "0  Born and raised in Houston, Texas, she perform...                  1  \n",
       "0  Managed by her father, Mathew Knowles, the gro...                  1  \n",
       "0  Their hiatus saw the release of Beyoncé's debu...                  1  \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  1  \n",
       "1  Born and raised in Houston, Texas, she perform...                  1  \n",
       "1  Managed by her father, Mathew Knowles, the gro...                  1  \n",
       "1  Their hiatus saw the release of Beyoncé's debu...                  1  \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  3  \n",
       "2  Born and raised in Houston, Texas, she perform...                  3  \n",
       "2  Managed by her father, Mathew Knowles, the gro...                  3  \n",
       "2  Their hiatus saw the release of Beyoncé's debu...                  3  \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  1  \n",
       "3  Born and raised in Houston, Texas, she perform...                  1  \n",
       "3  Managed by her father, Mathew Knowles, the gro...                  1  \n",
       "3  Their hiatus saw the release of Beyoncé's debu...                  1  \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  1  \n",
       "4  Born and raised in Houston, Texas, she perform...                  1  \n",
       "4  Managed by her father, Mathew Knowles, the gro...                  1  \n",
       "4  Their hiatus saw the release of Beyoncé's debu...                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squad = pd.read_csv(\n",
    "    \"cleaned_squad_data.csv\",\n",
    "    dtype = { \n",
    "        \"question\" : str,\n",
    "        \"context_paragraph\" : str,\n",
    "        \"answer\" : str,\n",
    "        \"answer_start\" : int,\n",
    "        \"answer_end\" : int,\n",
    "        \"answer_sent_index\" : int,\n",
    "        \"tokenized_context\" : str\n",
    "    },\n",
    "    converters = {\"context_sentences\" : ast.literal_eval}\n",
    ")\n",
    "\n",
    "out=df_squad.explode(\"context_sentences\")\n",
    "out.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the cell contents are truncated, let's print out and examine one row in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In what city and state did Beyonce  grow up? ',\n",
       " 'context_paragraph': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'answer': 'Houston, Texas',\n",
       " 'answer_start': 166,\n",
       " 'answer_end': 180,\n",
       " 'context_sentences': ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress.',\n",
       "  \"Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child.\",\n",
       "  \"Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time.\",\n",
       "  'Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'],\n",
       " 'answer_sent_index': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squad.iloc[3].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get a better understanding of what each column means:\n",
    "* `question` is the question text.\n",
    "* `context_paragraph` is the paragraph of text that contains the answer, which our model extracts from.\n",
    "* `answer` is the ground-truth answer to the given question.\n",
    "* `answer_start` and `answer_end` are the indexes of the first and last character of `answer` within `context_paragraph`. In other words, `context_paragraph[answer_start:answer_end]` yields `answer`. Note that `answer_end` is not inclusive.\n",
    "* `context_sentences` is the list of sentences in `context_paragraph`.\n",
    "* `answer_sent_index` is the ground-truth index of the answer sentence within `context_sentences` (indexing starts from 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several techniques to build a question-answering model from this dataset, which we will introduce in the following sections. As you implement each technique, try to think about its advantage and disadvantage, as compared to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Unsupervised Models\n",
    "In this section, we will implement three unsupervised learning models to identify the sentence that contains the answer to a given question. Here \"unsupervised\" means that we will not make use of the ground truth answer provided in the dataset (i.e., the columns `text`, `answer_start`, and `answer_end`). Instead, the sentence identification will be based only on some pre-defined heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Jaccard Overlap\n",
    "The Jaccard overlap of two given sets $A$ and $B$ measures the similarity between them and is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "J(A, B) = \\begin{cases}\n",
    "    \\frac{|A \\cap B|}{|A \\cup B|} & \\text{ if $A \\ne \\emptyset$ or $B \\ne \\emptyset$ } \\\\\n",
    "    1 & \\text { otherwise }\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Given a question and a list of context sentences, we can identify the answer sentence using Jaccard overlap as follows:\n",
    "1. Construct the set of words that are in the input question; we will call this set $Q$.\n",
    "1. Construct the sets of words that are in each context sentence; we will call these sets $S_1, S_2, \\ldots, S_m$. Here $S_i$ is the set of words in the $i$-th context sentence.\n",
    "1. Return the index of the context sentence whose Jaccard overlap with the input question is largest; this is our predicted answer sentence: \n",
    "\n",
    "$$\\hat y = \\underset{1 \\le i \\le m}{\\operatorname{argmax}} J(Q, S_i).$$\n",
    "\n",
    "Implement the function `get_jaccard_prediction` that performs the above steps on the dataset `df_squad`. For every row, it stores the predicted answer sentence index in a new column `\"jaccard_prediction\"`, and the corresponding largest Jaccard overlap value in a new column `\"jaccard_value\"`.\n",
    "\n",
    "**Notes**:\n",
    "* Our math notations use 1-based indexing, but in your implementation the indexes start from 0. In other words, if the first sentence in the context paragraph is the predicted answer sentence, you should return 0.\n",
    "* If multiple context sentences have the same (largest) Jaccard overlap with the question, return the smallest sentence index.\n",
    "* To build the set of words from a sentence, you should first tokenize the sentence with `nltk`, and then turn the resulting list of tokens into a set.\n",
    "* You do not need to perform any rounding on the distance values.\n",
    "* Refer to the [Pandas primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/pandas-primer/pandas_primer.ipynb) on how to vectorize a row-wise dataframe operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x,y):\n",
    "   \n",
    "    x=set(word_tokenize(x[0]))\n",
    "  \n",
    "    if x is not None and y is not None:\n",
    "        A=len(x.intersection(y))\n",
    "        B=len(x.union(y))\n",
    "        return A/B\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_jaccard_value(df_list,question):\n",
    "    #question is a set of words\n",
    "    temp=pd.DataFrame(df_list).astype(str)\n",
    "    \n",
    "    temp=temp.apply(lambda x: jaccard(x,question),axis=1)\n",
    "    \n",
    "    \n",
    "    value=temp.max()\n",
    "    \n",
    "    index=temp.idxmax()\n",
    "   \n",
    "    return (value,index)\n",
    "    \n",
    "\n",
    "def get_jaccard_prediction(df_squad):\n",
    "    \"\"\"\n",
    "    Identify the answer sentence as one that has the largest Jaccard overlap with the input question.\n",
    "    \n",
    "    args:\n",
    "        df_squad (pd.DataFrame) : a copy of the SQuAD dataset\n",
    "        \n",
    "    returns:\n",
    "        pd.DataFrame : the input dataframe with two additional columns, \"jaccard_prediction\" and \"jaccard_value\"\n",
    "    \"\"\"\n",
    "    df_squad[\"question\"]=df_squad[\"question\"].apply(lambda x: set(word_tokenize(x)))\n",
    "    \n",
    "    df_squad[\"temp\"]=df_squad.apply(lambda x: get_jaccard_value(x['context_sentences'], x['question']), \n",
    "                        axis=1)\n",
    "    df_squad[[\"jaccard_value\", 'jaccard_prediction']] = pd.DataFrame(df_squad['temp'].tolist(), index=df_squad.index)\n",
    "    df_squad=df_squad.drop('temp', axis=1)\n",
    "    return df_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 355.77it/s]\n",
      " 55%|█████▍    | 47322/86821 [01:24<01:10, 558.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a601a49e9a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All tests passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtest_get_jaccard_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-a601a49e9a41>\u001b[0m in \u001b[0;36mtest_get_jaccard_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"\"\"Test on the entire dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdf_jaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jaccard_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcheck_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_jaccard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m86821\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a6d2619b9d2>\u001b[0m in \u001b[0;36mget_jaccard_prediction\u001b[0;34m(df_squad)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     df_squad[\"temp\"]=df_squad.progress_apply(lambda x: get_jaccard_value(x['context_sentences'], x['question']), \n\u001b[0;32m---> 40\u001b[0;31m                         axis=1)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jaccard_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jaccard_prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8740\u001b[0m         )\n\u001b[0;32m-> 8741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a6d2619b9d2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     df_squad[\"temp\"]=df_squad.progress_apply(lambda x: get_jaccard_value(x['context_sentences'], x['question']), \n\u001b[0m\u001b[1;32m     40\u001b[0m                         axis=1)\n\u001b[1;32m     41\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jaccard_value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jaccard_prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a6d2619b9d2>\u001b[0m in \u001b[0;36mget_jaccard_value\u001b[0;34m(df_list, question)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8740\u001b[0m         )\n\u001b[0;32m-> 8741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a6d2619b9d2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-5a6d2619b9d2>\u001b[0m in \u001b[0;36mjaccard\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_get_jaccard_prediction():\n",
    "    \"\"\"Test on the first 10 rows\"\"\"\n",
    "    df_jaccard = get_jaccard_prediction(df_squad.head(10).copy())\n",
    "    \n",
    "    check_equal(df_jaccard.shape, (10, 9))\n",
    "    \n",
    "    check_approx(df_jaccard[\"jaccard_value\"].tolist(),[\n",
    "        0.0, 0.046511627906976744, 0.15, 0.03225806451612903, 0.02040816326530612,\n",
    "        0.18421052631578946, 0.10869565217391304, 0.12, 0.05263157894736842, 0.10256410256410256\n",
    "    ])\n",
    "    \n",
    "    check_equal(df_jaccard[\"jaccard_prediction\"].tolist(), [0, 1, 1, 0, 3, 1, 3, 2, 1, 1])\n",
    "    \n",
    "    jaccard_accuracy = (df_jaccard[\"jaccard_prediction\"] == df_jaccard[\"answer_sent_index\"]).values.mean()\n",
    "    check_equal(jaccard_accuracy, 0.6)\n",
    "\n",
    "    \n",
    "    \"\"\"Test on the entire dataset\"\"\"\n",
    "    df_jaccard = get_jaccard_prediction(df_squad.copy())\n",
    "    \n",
    "    check_equal(df_jaccard.shape, (86821, 9))\n",
    "    \n",
    "    check_approx(df_jaccard.tail(10)[\"jaccard_value\"].tolist(), [\n",
    "        0.11428571428571428, 0.17073170731707318, 0.08333333333333333, 0.10526315789473684, 0.125,\n",
    "        0.10714285714285714, 0.04, 0.07407407407407407, 0.07142857142857142, 0.08333333333333333\n",
    "    ])\n",
    "    \n",
    "    check_equal(df_jaccard.tail(10)[\"jaccard_prediction\"].tolist(), [0, 0, 0, 4, 4, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    jaccard_accuracy = (df_jaccard[\"jaccard_prediction\"] == df_jaccard[\"answer_sent_index\"]).values.mean()\n",
    "    check_approx(jaccard_accuracy, 0.7001992605475634)\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_get_jaccard_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the Jaccard technique is saying \"the context sentence that is most similar to the question contains the answer.\" We see that even such a simple heuristic can achieve 70% accuracy, which is not bad at all. This performance can be improved a bit if we take the time to preprocess (e.g., remove stopwords, lemmatize tokens) in the questions and context sentences, before computing the Jaccard overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: TF-IDF Vectors\n",
    "Instead of Jaccard overlap, we can employ other measures of similarity, such as the Euclidean distance:\n",
    "\n",
    "$$d_{\\text{euclidean}}(a, b) = \\|a - b\\|_2 = \\sqrt{\\sum_{i=1}^k (a_i - b_i)^2}.$$\n",
    "\n",
    "To compute this distance, we first need to convert each question and context sentence into a vector. Recall from earlier projects that one way to do so is building a TF-IDF model, which transforms each string into a vector $v \\in \\mathbb{R}^k$ where:\n",
    "* $k$ is the number of unique tokens in the entire dataset.\n",
    "* The $i$-th element is the frequency of token $i$ in the string, divided by its IDF value.\n",
    "\n",
    "Given a question, a list of context sentences, and a trained TF-IDF model, we can identify the answer sentence as follows:\n",
    "1. Transform the question into a vector $u$ using the TF-IDF model.\n",
    "1. Transform each context sentence $s_i$ into a vector $v_i$ using the TF-IDF model.\n",
    "1. Return the index of the context sentence whose Euclidean distance to the input question is smallest in the TF-IDF space:\n",
    "\n",
    "$$\\hat y = \\underset{1 \\le i \\le m}{\\operatorname{argmin}} d_{\\text{euclidean}}(u, v_i).$$\n",
    "\n",
    "Implement the function `get_tfidf_prediction` that performs the above steps on the dataset `df_squad`. For every row, it stores the predicted answer sentence index in a new column `\"tfidf_prediction\"`, and the corresponding smallest Euclidean distance value in a new column `\"distance_value\"`.\n",
    "\n",
    "**Notes**:\n",
    "* Since the input `tfidf_vectorizer` is already trained, you don't need to fit it on anything. Instead, just call `.transform` on the appropriate question / context sentence.\n",
    "* If multiple context sentences have the same (smallest) distance value from the question, return the smallest sentence index.\n",
    "* You may find that using `df.apply(<your_custom_function>, axis = 1)` to process every row is quite slow, due to the complexity of the operations involved. To work around this issue, try to think about how to completely vectorize this function, using only built-in Pandas and NumPy/Scipy or Sklearn operations.\n",
    "* You may find the Pandas method `.explode()` helpful. Note that there are duplicate questions in the dataset (the same question may apply to different context paragraphs), so be careful when performing groupby on the exploded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_prediction(df_squad0, tfidf_vectorizer):\n",
    "    \"\"\"\n",
    "    Identify the answer sentence as one whose TF-IDF representation has minimal distance to that of the question.\n",
    "    \n",
    "    args:\n",
    "        df_squad (pd.DataFrame) : a copy of the SQuAD dataset\n",
    "        tfidf_vectorizer (sklearn.feature_extraction.text.TfidfVectorizer) :\n",
    "            the TF-IDF model to transform questions and sentences\n",
    "        \n",
    "    returns:\n",
    "        pd.DataFrame : the input dataframe with two additional columns, \"tfidf_prediction\" and \"distance_value\"\n",
    "    \"\"\"\n",
    "    \n",
    "    df_squad=df_squad0.explode(\"context_sentences\")\n",
    "    #df_squad[\"question\"]=df_squad[\"question\"].astype(\"str\")\n",
    "    #df_squad[\"context_sentences\"]=df_squad[\"context_sentences\"].astype(\"str\")\n",
    "    df_squad[\"question\"]=df_squad[\"question\"].apply(lambda x: tfidf_vectorizer.transform([x]))\n",
    "    df_squad[\"context_sentences\"]=df_squad[\"context_sentences\"].apply(lambda x: tfidf_vectorizer.transform([x]))\n",
    "    new=df_squad.apply(lambda x:euclidean_distances(x['context_sentences'], x['question'])[0][0],axis=1)\n",
    "    new.index = pd.MultiIndex.from_arrays([new.index, new.groupby(new.index).cumcount()], names=['index','index2'])\n",
    "    df_squad0[\"distance_value\"]=new.groupby(level=0).min()\n",
    "    \n",
    "    #print(new.groupby(level=0).idxmin().str[1])\n",
    "    df_squad0[\"tfidf_prediction\"]=new.groupby(level=0).idxmin().str[1]\n",
    "    #=df_squad.groupby(['question','temp']).max()\n",
    "    \n",
    "    #print(df_squad0[\"distance_value\"].tolist())\n",
    "   \n",
    "    return df_squad0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example trained TF-IDF vectorizer that we can use. Since fitting it on the entire dataset takes a while, we will initialiize and fit it in the global namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  \"The parameter 'token_pattern' will not be used\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=10, ngram_range=(1, 2),\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function word_tokenize at 0x7fe3f3649ef0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer = nltk.word_tokenize,\n",
    "    stop_words = stopwords.words('english'),\n",
    "    ngram_range = (1,2),\n",
    "    max_df = 1.0,\n",
    "    min_df = 10\n",
    ")\n",
    "tfidf_vectorizer.fit(df_squad[\"context_paragraph\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-da5aff263ff9>\u001b[0m in \u001b[0;36mtest_get_tfidf_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"\"\"Test on the whole dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf_tf_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tfidf_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcheck_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tf_idf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m86821\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-dbbba8d170a1>\u001b[0m in \u001b[0;36mget_tfidf_prediction\u001b[0;34m(df_squad0, tfidf_vectorizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#df_squad[\"question\"]=df_squad[\"question\"].astype(\"str\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#df_squad[\"context_sentences\"]=df_squad[\"context_sentences\"].astype(\"str\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m                 )\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-dbbba8d170a1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#df_squad[\"question\"]=df_squad[\"question\"].astype(\"str\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#df_squad[\"context_sentences\"]=df_squad[\"context_sentences\"].astype(\"str\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_squad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1810\u001b[0m             \u001b[0minplace_csr_row_normalize_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0minplace_csr_row_normalize_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_get_tfidf_prediction():\n",
    "    \"\"\"Test on the first 10 rows\"\"\"\n",
    "    df_tf_idf = get_tfidf_prediction(df_squad.head(10).copy(), tfidf_vectorizer)\n",
    "    \n",
    "    check_equal(df_tf_idf.shape, (10, 9))\n",
    "    \n",
    "    check_approx(df_tf_idf[\"distance_value\"].tolist(), [\n",
    "        1.4142135623730951, 1.4142135623730951, 1.118805210307003, 1.414213562373095,\n",
    "        1.414213562373095, 1.0991965705062294, 1.2823059131390453, 1.1299491754496973,\n",
    "        1.3217983153692023, 1.1364153055563095\n",
    "    ])\n",
    "    \n",
    "    print(\"passed!\")\n",
    "   \n",
    "    \"\"\"Test on the whole dataset\"\"\"\n",
    "    df_tf_idf = get_tfidf_prediction(df_squad.copy(), tfidf_vectorizer)\n",
    "    \n",
    "    check_equal(df_tf_idf.shape, (86821, 9))\n",
    "    \n",
    "    check_approx(df_tf_idf.tail(10)[\"distance_value\"].tolist(), [\n",
    "        1.2205482532513834, 1.1011579092263701, 1.23935316383152, 1.2848863907388077,\n",
    "        1.1456258185112482, 1.2657059224645815, 1.4142135623730951, 1.2768968376533885,\n",
    "        1.2666294346869091, 1.4142135623730951\n",
    "    ])\n",
    "    \n",
    "    tfidf_accuracy = (df_tf_idf[\"tfidf_prediction\"] == df_tf_idf[\"answer_sent_index\"]).values.mean()\n",
    "    assert 0.68 <= round(tfidf_accuracy, 2) <= 0.69, tfidf_accuracy\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "%time test_get_tfidf_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is sufficiently optimized, you should expect to see the local test being finished in about 3.5 minutes or less, on a `Standard_NC6` GPU Compute. If your code runs for more than 7 minutes, you should try to improve its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still see a training accuracy of about 0.68, so TF-IDF is fairly similar in performance to the baseline Jaccard model.\n",
    "\n",
    "Up until now we have used language models that rely only on word frequencies, without considering the meaning of the words themselves. Now we will address this shortcoming by considering the *word embedding* of each word in our corpus.  Roughly speaking, a word embedding is a vector representation of that word in some space $\\mathbb{R}^k$. This representation differs from the TF-IDF transformation in two important ways:\n",
    "\n",
    "1. If two words have similar meanings in some sense, their Euclidean distances should be close. For example, we may expect the word `\"Pittsburgh\"` to be closer, in Euclidean distance, to `\"Chicago\"` than to `\"Pikachu\"`, because the first two are city names while the third is a Pokemon.\n",
    "1. The dimensionality of the vector $k$ is fixed and typically much smaller than the vocabulary size.\n",
    "\n",
    "While these features sound promising, constructing word embeddings requires a very large amount of data (you need to see `\"Pittsburgh\"` and `\"Chicago\"` appear together in overlapping context enough times for the model to learn that they are similar). The algorithms to train word embedding models are unfortunately beyond the scope of this course, as they involve many machine learning theories we haven't covered.\n",
    "\n",
    "That said, there are many powerful pre-trained models that we can use. These models have been trained on huge amounts of data and encode a lot of information about the meanings of the words. The first pre-trained model we will use is one from the [SentenceTransformer library](https://github.com/UKPLab/sentence-transformers#getting-started) called `'distilbert-base-nli-stsb-mean-tokens'`. Once loaded, it can encode a collection of strings, yielding a matrix where each row is the vector embedding of one string.\n",
    "\n",
    "Run the following cell to see the model in action. Note that the first time you do so, it may take some time to download the model. Also note that the embedding matrix is a dense NumPy matrix, rather than a sparse Scipy matrix like what TF-IDF outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 768)\n",
      "[[-0.2148625   0.39572328  0.46908733 ... -0.23118979 -0.49579197\n",
      "   0.42366397]\n",
      " [-0.4400176  -0.28488502  0.23363824 ...  0.11956129 -0.16530187\n",
      "  -0.08625093]\n",
      " [-0.29504895 -0.24928904 -0.02407134 ...  0.11944669  0.00626751\n",
      "   1.0400684 ]]\n"
     ]
    }
   ],
   "source": [
    "sent_transformer = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "embedding = sent_transformer.encode([\n",
    "    'This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.'\n",
    "])\n",
    "print(embedding.shape)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Sent2vec Encoders\n",
    "Here we will follow roughly the same procedure as in the previous question: first convert the questions and context sentences into vectors using `sent_transformer`, then identify the context sentence whose vector representation is closest in Euclidean distance to that of the input question. However, one important caveat is that encoding the questions and context sentences with `sent_transformer` takes a lot longer (as much as 10 times longer) than with `tfidf_vectorizer`, because this encoding is actually the forward pass through a pre-trained neural network. To address this issue, we recommend the following outline for your implementation:\n",
    "\n",
    "1. Construct a mapping from each unique question / context sentence to its vector encoding.\n",
    "1. Use this mapping to compute the vector representation of every question / context sentence in the dataset.\n",
    "1. Compute the Euclidean distances between the questions and context sentences to identify the answer sentence index for each question.\n",
    "\n",
    "The key idea is that there are some duplicate questions and many duplicate context sentences (since several questions share the same context paragraph), so you want to store the encoding of each unique question / context sentence to avoid recomputing them several times. This same idea also applies to Question 2, although repeated computations are not as big of an issue there since TF-IDF transformations are fast.\n",
    "\n",
    "Implement the function `get_sent2vec_prediction` that performs the above steps on the dataset `df_squad`. For every row, it stores the predicted answer sentence index in a new column `\"sent2vec_prediction\"`, and the corresponding smallest Euclidean distance value in a new column `\"distance_value\"`.\n",
    "\n",
    "**Notes**:\n",
    "* When working with only the values of a Series (e.g., a dataframe column) and do not care about its name or indices, calling the `.values` attribute to convert it to a NumPy array may provide some speed-up.\n",
    "* If multiple context sentences have the same (smallest) distance value from the question, return the smallest sentence index.\n",
    "* You should encode the entire set of unique questions / context sentences at once, rather then encoding each of them individually in a loop. Due to the encoder's internal implementation, you will get different embedding results if you encode each question / context sentence individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent2vec_prediction(df_squad, encoder):\n",
    "    \"\"\"\n",
    "    Identify the answer sentence as one whose Sent2vec representation has minimal distance to that of the question.\n",
    "    \n",
    "    args:\n",
    "        df_squad (pd.DataFrame) : a copy of the SQuAD dataset\n",
    "        encoder (SentenceTransformer) :\n",
    "            the Sent2vec encoder used to transform questions and sentences into their word embeddings\n",
    "        \n",
    "    returns: Tuple(question_embeddings, context_embeddings, df_sent2vec)\n",
    "        question_embeddings (Dict[str, np.ndarray]) :\n",
    "            a mapping between each unique question and its Sent2vec embedding\n",
    "        context_embeddings (Dict[str, np.ndarray]) :\n",
    "            a mapping between each unique context sentence and its Sent2vec embedding\n",
    "        df_sent2vec (pd.DataFrame) :\n",
    "            the input dataframe with two additional columns, \"sent2vec_prediction\" and \"distance_value\"\n",
    "    \"\"\"\n",
    "    new=df_squad.explode(\"context_sentences\")\n",
    "    \n",
    "    print(\"begin2\")\n",
    "    list_q=pd.unique(df_squad.question).tolist()\n",
    "    print(\"begin3\")\n",
    "    list_s=pd.unique(new.context_sentences).tolist()\n",
    "\n",
    "    #bar=len(list_q)\n",
    "    print(\"begin4\")\n",
    "    val1=encoder.encode(list_q)\n",
    "    val2=encoder.encode(list_s)\n",
    "    print(\"m\")\n",
    "\n",
    "    map_q=dict(zip(list_q,val1))\n",
    "    map_s=dict(zip(list_s,val2))\n",
    "    print(\"m\")\n",
    "    \n",
    "    \n",
    "    #list_q[\"out\"]=list_q.apply(lambda x: encoder.encode(x)[0],axis=1)\n",
    "    #list_s[\"out\"]=list_s.apply(lambda x: encoder.encode(x)[0],axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    " \n",
    "    new=new.progress_apply(lambda x:euclidean(map_s[x['context_sentences']], map_q[x['question']]),axis=1)\n",
    "    #print(new)\n",
    "    df_squad[\"distance_value\"]=new.groupby(level=0).min()\n",
    "    \n",
    "   \n",
    "    return map_q,map_s,df_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01007706 -0.376328    0.93960816 -0.5805885   0.10827739  0.25717485\n",
      "  0.6128501   0.5031226  -0.4418595   0.4174892 ]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "[-0.01007706 -0.376328    0.93960816 -0.5805885   0.10827739  0.25717485\n  0.6128501   0.5031226  -0.4418595   0.4174892 ]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-1109e6d7e6e5>\u001b[0m in \u001b[0;36mtest_get_sent2vec_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mquestion_embeddings_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         [-0.01007791, -0.37632802,  0.93960756, -0.5805886 ,  0.1082769 ,\n\u001b[0;32m---> 19\u001b[0;31m         0.25717542,  0.61284965,  0.5031233 , -0.44185746,  0.4174885 ]\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3830400b124f>\u001b[0m in \u001b[0;36mcheck_approx\u001b[0;34m(actual, expected)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: [-0.01007706 -0.376328    0.93960816 -0.5805885   0.10827739  0.25717485\n  0.6128501   0.5031226  -0.4418595   0.4174892 ]"
     ]
    }
   ],
   "source": [
    "def test_get_sent2vec_prediction():\n",
    "    \"\"\"Test on the first 10 rows\"\"\"\n",
    "    question_embeddings_map, context_embeddings_map, df_sent2vec = \\\n",
    "        get_sent2vec_prediction(df_squad.head(10).copy(), sent_transformer)\n",
    "    \n",
    "    question = 'When did Beyoncé rise to fame?'\n",
    "    check_approx(\n",
    "        question_embeddings_map[question][:10],\n",
    "        [-0.32787466, -0.1555715 ,  0.6588354 , -0.6630659 ,  0.58848995,\n",
    "         -0.04990903,  0.49315828,  0.24733946, -0.2781973 ,  0.60307765]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    question = 'In what city and state did Beyonce  grow up? '\n",
    "    print(question_embeddings_map[question][:10])\n",
    "    check_approx(\n",
    "        question_embeddings_map[question][:10],\n",
    "        [-0.01007791, -0.37632802,  0.93960756, -0.5805886 ,  0.1082769 ,\n",
    "        0.25717542,  0.61284965,  0.5031233 , -0.44185746,  0.4174885 ]\n",
    "    )\n",
    "    \n",
    "    context = \"Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child.\"\n",
    "    check_approx(\n",
    "        context_embeddings_map[context][:10],\n",
    "        [-0.10903959, -0.27940086,  0.23572135,  0.5180772 ,  0.35532874,\n",
    "        0.13151167,  0.17776611, -0.4766906 , -0.09587531,  0.93431026]\n",
    "    )\n",
    "    \n",
    "    context = \"Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time.\"\n",
    "    check_approx(\n",
    "        context_embeddings_map[context][:10],\n",
    "        [-0.80261433,  0.13804385,  0.59162873,  0.39244094, -0.27683446,\n",
    "        0.4693975 ,  0.41246495,  0.3003438 , -1.0914499 , -0.17863718]\n",
    "    )\n",
    "    \n",
    "    check_approx(\n",
    "        df_sent2vec[\"distance_value\"],\n",
    "        [12.849678993225098, 13.180706977844238, 11.950626373291016, 13.0397310256958,\n",
    "         12.867681503295898, 13.494369506835938, 15.975933074951172, 17.264522552490234,\n",
    "         12.373723030090332, 12.654834747314453]\n",
    "    )\n",
    "    \n",
    "    print(\"Passed!\")\n",
    "    \n",
    "    \"\"\"Test on the full dataset\"\"\"\n",
    "    question_embeddings_map, context_embeddings_map, df_sent2vec = \\\n",
    "        get_sent2vec_prediction(df_squad.copy(), sent_transformer)\n",
    "    \n",
    "    question = 'What is KMC an initialism of?'\n",
    "    check_approx(\n",
    "        question_embeddings_map[question][:10],\n",
    "        [-0.9376349 ,  0.07794607, -0.08829201,  0.23485802,  0.05154163,\n",
    "         -0.11316115, -0.15181658,  0.69910896,  0.43863776, -0.5214241]\n",
    "    )\n",
    "    \n",
    "    question = 'In what year did Kathmandu create its initial international relationship?'\n",
    "    check_approx(\n",
    "        question_embeddings_map[question][:10],\n",
    "        [0.20806803,  0.5848249 ,  0.51129144, -0.8319231 ,  0.10700534,\n",
    "        0.35735554,  0.4291537 ,  1.0774763 , -0.12320331,  0.5771949 ]\n",
    "    )\n",
    "    \n",
    "    context = \"KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States.\"\n",
    "    check_approx(\n",
    "        context_embeddings_map[context][:10],\n",
    "        [0.65290284,  0.1876768 ,  0.5210961 , -0.13445881, -0.05164678,\n",
    "        0.5333182 ,  0.6115602 ,  0.6255963 ,  0.38067245, -0.10421762]\n",
    "    )\n",
    "    \n",
    "    context = 'It was established in 1972 and started to impart medical education from 1978.'\n",
    "    check_approx(\n",
    "        context_embeddings_map[context][:10],\n",
    "        [0.72947043, -0.5591796 ,  0.86937994, -0.80692345, -0.05610372,\n",
    "        0.07088739,  1.1165347 ,  0.8680078 ,  0.04112893, -0.71701765]\n",
    "    )\n",
    "    check_approx(\n",
    "        df_sent2vec[\"distance_value\"].tail(10),\n",
    "        [11.888211250305176, 13.456267356872559, 14.015336990356445, 14.333199501037598,\n",
    "         11.331104278564453, 10.903414726257324, 17.290882110595703, 14.260327339172363,\n",
    "         13.246850967407227, 16.56328582763672]\n",
    "    )\n",
    "    \n",
    "    sent2vec_accuracy = (df_sent2vec[\"sent2vec_prediction\"] == df_sent2vec[\"answer_sent_index\"]).mean()\n",
    "    check_equal(round(sent2vec_accuracy, 2), 0.68)\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "    print(\"Saving the embedding to pickle files for later use ...\")\n",
    "    with open(\"question_embeddings_map.pkl\", \"wb\") as f1, open(\"context_embeddings_map.pkl\", \"wb\") as f2:\n",
    "        pickle.dump(question_embeddings_map, f1)\n",
    "        pickle.dump(context_embeddings_map, f2)\n",
    "    print(\"Done!\")\n",
    "        \n",
    "%time test_get_sent2vec_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is sufficiently optimized, you should expect to see the local test finished in about 7.5 minutes or less, on a `Standard_NC6` GPU Compute. If your code runs for more than 10 minutes, you should try to improve its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slight improvement in accuracy, compared to the previous two methods. It seems like using the meanings of the words isn't too effective here. Now we will try a different technique that utilizes the linguistic structures of the questions and context sentences. Let's walk through an example of what we will do first.\n",
    "\n",
    "Assume we have the following input `question`:\n",
    "\n",
    "```\n",
    "How many parameters does BERT-large have?\n",
    "```\n",
    "and `context`:\n",
    "```\n",
    "BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\n",
    "```\n",
    "\n",
    "We will perform the following steps:\n",
    "1. Lowercase `question` and identify its *root word*:\n",
    "```py\n",
    "question_root = \"have\"\n",
    "```\n",
    "1. Lemmatize this root word to reduce it to its base form.\n",
    "```py\n",
    "lemmatized_question_root = \"have\"\n",
    "```\n",
    "1. Split `context` into context sentences and lowercase them:\n",
    "```py\n",
    "sent1 = \"bert-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340m parameters!\"\n",
    "sent2 = \"altogether it is 1.34gb, so expect it to take a couple minutes to download to your colab instance.\"\n",
    "```\n",
    "1. Identify the *noun chunks* in each context sentence:\n",
    "```py\n",
    "sent1_ncs = [\"it\", \"24-layers\", \"an embedding size\", \"a total\", \"340m\", \"parameters\"]\n",
    "sent2_ncs = [\"it\", \"1.34gb\", \"it\", \"a couple minutes\", \"your colab instance\"]\n",
    "```\n",
    "1. Extract the *root word* from each noun chunk:\n",
    "```py\n",
    "sent1_nc_roots = [\"it\", \"layers\", \"size\", \"total\", \"m\", \"parameters\"]\n",
    "sent2_nc_roots = [\"it\", \"gb\", \"it\", \"minutes\", \"instance\"]\n",
    "```\n",
    "1. Identify and lemmatize the *head* for each of the above root words. Store these heads into sets:\n",
    "```py\n",
    "sent1_nc_root_heads = {\"have\", \"for\", \"layer\", \"of\"}\n",
    "sent2_nc_root_heads = {\"is\", \"take\", \"to\"}\n",
    "```\n",
    "1. Return the index of the first context sentence whose `nc_root_heads` set contains the question's root word `lemmatized_question_root`. If no context sentence meets this requirement, return 0 (in other words, we predict that the first context sentence is the answer, based on the assumption that the first sentence in a paragraph typically contains the most important information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define some global variables that will be employed in this task. In particular, we will use the `en_core_web_sm` model from spaCy, and the part-of-speech lemmatization procedure from Project 4. Note: the autograder will use this cell so do not change its content and do not add the tag `excluded_from_script`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pos_mapping = {\n",
    "    'ADJ' : wordnet.ADJ, 'NOUN' : wordnet.NOUN,\n",
    "    'VERB' : wordnet.VERB, 'ADP' : wordnet.ADV\n",
    "}\n",
    "\n",
    "def lemmatize_token(token):\n",
    "    \"\"\"\n",
    "    Lemmatize a spaCy token based on its part-of-speech tag. If a tag is not recognized, treat it as a noun.\n",
    "    \n",
    "    args:\n",
    "        token (spacy.tokens.token.Token) : an output token when inputting a raw string to a spaCy model\n",
    "    \n",
    "    return:\n",
    "        str : the lemmatized string\n",
    "    \"\"\"\n",
    "    return lemmatizer.lemmatize(token.text, pos = pos_mapping.get(token.pos_, wordnet.NOUN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we recommend consulting the [AST primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/ast-primer/ast_primer.ipynb) and the [spaCy documentation](https://spacy.io/usage/linguistic-features) to replicate the above example in code. Once you have successfully done so, proceed to the next question.\n",
    "\n",
    "**Notes**:\n",
    "* To identify a question's root word, you can input it to the `en_nlp` model, extract the first sentence from the `.sents` generator, and use the `.root` attribute. This returns a `Token` that you can then input to `lemmatize_token` to get the lemmatized form.\n",
    "* Remember to also lemmatize the heads of the root words for the noun chunks (in the above example, `sent1_nc_root_heads` and `sent2_nc_root_heads` contain lemmatized strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "question = \"How many parameters does BERT-large have?\"\n",
    "context_sentences = [\n",
    "    \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters!\",\n",
    "    \"Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Root word matching\n",
    "Implement the function `get_rootword_prediction` that performs the above steps on the dataset `df_squad`. For every row, it stores:\n",
    "* the predicted answer sentence index in a new column `\"rootword_prediction\"`\n",
    "* the lemmatized root word of the question in a new column `\"question_root\"`\n",
    "* the set of lemmatized heads of the root words for the noun chunks in the predicted context sentence (for the above example, this would be the set `sent1_nc_root_heads`) in a new column `\"nc_root_heads\"`.\n",
    "\n",
    "**Notes**:\n",
    "* Recall that the context paragraphs have already been split into sentences in the column `context_sentences`.\n",
    "* Remember to lower case all the questions and context sentences when doing root word matching (but do not change the original `question`, `context_paragraph` or `context_sentences` columns in `df_squad`).\n",
    "* If a question contains multiple sentences, make sure you extract the question root word from the first sentence, not the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def head_set(sent,nlp,word):\n",
    "    sent=pd.DataFrame({\"h\":sent})\n",
    "    print(word)\n",
    "    sent[\"w\"]=sent.h.apply(lambda x: set(lemmatize_token(word.root.head) for word in nlp(x.lower()).noun_chunks))\n",
    "    sent[\"m\"]=sent.w.apply(lambda x: int(word in x))\n",
    "    #print(sent.m)\n",
    "    index=sent.m.argmax()\n",
    "    \n",
    "    return index,sent.w[index]\n",
    "'''\n",
    "def get_rootword_prediction(df_squad, en_nlp):\n",
    "    \"\"\"\n",
    "    Identify the answer sentence as the first sentence whose list of heads of the root words for its noun chunks\n",
    "    contains the question's root word.\n",
    "    \n",
    "    args:\n",
    "        df_squad (pd.DataFrame) : a copy of the SQuAD dataset\n",
    "        en_nlp (spacy.lang.en.English) : a pre-trained SpaCy language model\n",
    "    \n",
    "    returns:\n",
    "        pd.DataFrame : the input dataframe with three additional columns,\n",
    "            \"rootword_prediction\", \"question_root\" and \"nc_root_heads\"\n",
    "            \n",
    "    df_squad[\"question_root\"]=df_squad.question.apply(lambda x: lemmatize_token([sent.root for sent in en_nlp(x.lower()).sents][0]))\n",
    "    df_squad[\"nc_root_heads\"]=df_squad.apply(lambda x:head_set(x['context_sentences'], en_nlp,x['question_root']),axis=1)\n",
    "    df_squad[[\"rootword_prediction\",\"nc_root_heads\"]] = pd.DataFrame(df_squad[\"nc_root_heads\"].tolist(),index=df_squad.index)\n",
    "    return df_squad\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "compete\n",
      "leave\n",
      "grow\n",
      "become\n",
      "in\n",
      "make\n",
      "manage\n",
      "rise\n",
      "have\n",
      "[{'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'become', 'by', 'of'}, {'to', 'as', 'of', 'in', 'houston', 'perform'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "[{'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'become', 'by', 'of'}, {'to', 'as', 'of', 'in', 'houston', 'perform'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-a38243c42d29>\u001b[0m in \u001b[0;36mtest_rootword_prediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'singer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'giselle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'producer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'songwriter'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'singer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'giselle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'producer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'songwriter'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m{\u001b[0m\u001b[0;34m'singer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'giselle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'producer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'songwriter'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     ])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3830400b124f>\u001b[0m in \u001b[0;36mcheck_equal\u001b[0;34m(actual, expected)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: [{'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'become', 'by', 'of'}, {'to', 'as', 'of', 'in', 'houston', 'perform'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}, {'producer', 'songwriter', 'carter', 'singer', 'is'}]"
     ]
    }
   ],
   "source": [
    "def test_rootword_prediction():\n",
    "    \"\"\"Test on the first 10 rows\"\"\"\n",
    "    df_rootword = get_rootword_prediction(df_squad.head(10).copy(), en_nlp)\n",
    "    check_equal(df_rootword.shape, (10, 10))\n",
    "    print(df_rootword[\"nc_root_heads\"].tolist())\n",
    "    check_equal(df_rootword[\"rootword_prediction\"].tolist(), [0, 0, 0, 0, 2, 1, 0, 0, 0, 0])\n",
    "    \n",
    "    check_equal(df_rootword[\"nc_root_heads\"].tolist(), [\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'father', 'of', 'by', 'become'},\n",
    "        {'as', 'perform', 'of', 'in', 'to'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'},\n",
    "        {'singer', 'is', 'giselle', 'producer', 'songwriter'}\n",
    "    ])\n",
    "    \n",
    "    check_equal(df_rootword[\"question_root\"].tolist(), [\n",
    "        'start', 'compete', 'leave', 'grow', 'become',\n",
    "        'in', 'make', 'manage', 'rise', 'have'\n",
    "    ])\n",
    "    \n",
    "    \"\"\"Test on 5000 sampled data points\"\"\"\n",
    "    df_rootword = get_rootword_prediction(df_squad.sample(5000, random_state = 0).copy(), en_nlp)\n",
    "    check_equal(df_rootword.shape, (5000, 10))\n",
    "    \n",
    "    check_equal(df_rootword[\"rootword_prediction\"].value_counts().to_dict(), \n",
    "        {0: 3582, 1: 491, 2: 381, 3: 238, 4: 164, 5: 66, 6: 42,\n",
    "         7: 18, 8: 7, 9: 5, 10: 2, 12: 1, 13: 1, 21: 1, 11: 1}\n",
    "    )\n",
    "    \n",
    "    check_equal(df_rootword[\"rootword_prediction\"].tail(10).tolist(), [0, 1, 3, 0, 0, 0, 0, 2, 0, 4])\n",
    "    \n",
    "    check_equal(df_rootword[\"question_root\"].tail(10).tolist(), [\n",
    "        'see', 'kill', 'in', 'vote', 'wa', 'is', 'say', 'wa', 'compile', 'assign'\n",
    "    ])\n",
    "    \n",
    "    check_equal(df_rootword[\"nc_root_heads\"].tail(10).tolist(), [\n",
    "        {'announce', 'by', 'from', 'heed', 'in', 'live'},\n",
    "        {'destroy', 'in', 'kill', 'of'},\n",
    "        {'are', 'in', 'park'},\n",
    "        {'be', 'of'},\n",
    "        {'at', 'by', 'hold', 'in', 'missouri', 'of', 'on'},\n",
    "        {'achieve', 'as', 'have', 'iannis', 'in', 'of', 'on', 'with', 'xenakis'},\n",
    "        {'at', 'be', 'confirm', 'derive', 'of', 'show'},\n",
    "        {'after', 'by', 'find', 'love', 'of', 'say', 'wa'},\n",
    "        {'architect', 'artist', 'attract', 'from', 'in', 'of', 'qutb', 'ruler', 'through'},\n",
    "        {'assign', 'at', 'be', 'by', 'glanville', 'like', 'manage', 'of', 'teach', 'wa', 'with'}\n",
    "    ])\n",
    "    \n",
    "    accuracy = (df_rootword[\"rootword_prediction\"] == df_rootword[\"answer_sent_index\"]).values.mean()\n",
    "    check_equal(accuracy, 0.455)\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "%time test_rootword_prediction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this procedure takes a very long time, we only tested it on a random sample of 5000 data points. If your code is sufficiently optimized, the local test should finish in about 4 minutes on a `Standard_NC6` compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Supervised Models\n",
    "So far we have been exploring unsupervised methods for answer extraction which involves dividing the questions and contexts into tokens and projecting those tokens into a common representation space. You may notice that their performances weren't particularly great because we didn't perform any training on the dataset; instead, we only used pre-defined heuristics and pre-trained models. From this point, we will move to the supervised learning domain, where we make use of the ground-truth answers and build models that learn from these answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Preparing dataset for supervised learning\n",
    "We will first consider a binary classification setting, where we are given a question and a context sentence, and need to predict whether this context sentence contains the answer. In this setting, we can get several training data points from each row in the original dataset `df_squad`. In particular, if a row in `df_squad` looks like the following:\n",
    "\n",
    "|question|context_sentences|answer_sent_index|\n",
    "|---|---|---|\n",
    "|`q`|`[s0, s1, s2, s3]`|2|\n",
    "\n",
    "then it contributes four data points:\n",
    "\n",
    "|question|context_sentence|is_answer_sent|\n",
    "|---|---|---|\n",
    "|`q`|`s0`|0|\n",
    "|`q`|`s1`|0|\n",
    "|`q`|`s2`|1|\n",
    "|`q`|`s3`|0|\n",
    "\n",
    "More generally, a row in `df_squad` where the `context_sentences` list has `n` sentences will be transformed into `n` rows, one for each context sentence. Among these new rows, only the row at index `answer_sent_index` gets assigned the label 1, while the others get the label 0.\n",
    "\n",
    "Implement the function `build_data_for_classification` that turns the original dataset `df_squad` into a dataframe with 3 columns -- `question`, `context_sentence` and `is_answer_sent` -- using the procedure specified above.\n",
    "\n",
    "**Notes**:\n",
    "* Keep in mind that the new dataframe has a column named `context_sentence`, **not** `context_sentences`.\n",
    "* You should preserve the original row ordering in the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help(a,b):\n",
    "    a[b]=1\n",
    "    return a\n",
    "def build_data_for_classification(df_squad):\n",
    "    \n",
    "    df_squad[\"is_answer_sent\"]=df_squad.context_sentences.apply(lambda x: [0] * len(x))\n",
    "    df_squad[\"is_answer_sent\"]=df_squad.apply(lambda x:help(x[\"is_answer_sent\"],x['answer_sent_index']),axis=1)\n",
    "\n",
    "    new=df_squad[[\"question\",\"context_sentences\",\"is_answer_sent\"]].explode([\"context_sentences\",\"is_answer_sent\"])\n",
    "    new=new.rename(columns={\"context_sentences\": \"context_sentence\"})\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['context_sentence', 'is_answer_sent', 'question']\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_build_data_for_classification():\n",
    "    \"\"\"Test on 10 random rows\"\"\"\n",
    "    df_sample = df_squad.sample(n = 10, random_state = 0).copy()\n",
    "    df_formatted = build_data_for_classification(df_sample)\n",
    "    \n",
    "    assert df_formatted.shape == (48, 3), df_formatted.shape\n",
    "    print(sorted(df_formatted.columns))\n",
    "    assert sorted(df_formatted.columns) == ['context_sentence', 'is_answer_sent', 'question']\n",
    "    \n",
    "    assert df_formatted['is_answer_sent'].tolist() == [\n",
    "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "        1, 0, 0, 0, 1, 0, 1, 0\n",
    "    ], df_formatted['is_answer_sent'].tolist()\n",
    "    \n",
    "    # check that question orderings are preserved\n",
    "    assert (df_formatted[\"question\"].unique() == df_sample[\"question\"].unique()).all()\n",
    "    \n",
    "    \"\"\"Test on the full dataset\"\"\"\n",
    "    df_formatted = build_data_for_classification(df_squad.copy())\n",
    "    \n",
    "    assert df_formatted.shape == (443259, 3), df_formatted.shape\n",
    "    \n",
    "    assert df_formatted['is_answer_sent'].sample(n = 40, random_state = 200).tolist() == [\n",
    "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
    "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1\n",
    "    ], df_formatted['is_answer_sent'].tail(40).tolist()\n",
    "    \n",
    "    assert (df_formatted[\"question\"].unique() == df_squad[\"question\"].unique()).all()\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_build_data_for_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'question_embeddings_map.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6e459f5a608c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquestion_embeddings_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"question_embeddings_map.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontext_embeddings_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"context_embeddings_map.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     ) as handles:\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'question_embeddings_map.pkl'"
     ]
    }
   ],
   "source": [
    "question_embeddings_map = pd.read_pickle(\"question_embeddings_map.pkl\")\n",
    "context_embeddings_map = pd.read_pickle(\"context_embeddings_map.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "df_squad_train, df_squad_test = train_test_split(df_squad, train_size = 0.8, random_state = 0)\n",
    "df_train_formatted = build_data_for_classification(df_squad_train.reset_index())\n",
    "df_test_formatted = build_data_for_classification(df_squad_test.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Logistic Regression\n",
    "Having set up the dataset for binary classification, we can now train a logistic regression model. While the binary labels are already set up, we still need to construct the feature vectors as follows. For every question `q` and context sentence `s`:\n",
    "* Convert the question to its word embedding $x_q \\in \\mathbb{R}^k$, using the question embedding map from Question 3.\n",
    "* Convert the context sentence to its word embedding $x_s \\in \\mathbb{R}^l$, using the context embedding map from Question 3.\n",
    "* Concatenate these two vectors to get the input vector to the logistic regression model:\n",
    "\n",
    "$$x_{q,s} = (x_{q1} \\quad x_{q2} \\quad \\ldots \\quad x_{qk} \\quad x_{s1} \\quad x_{s2} \\quad \\ldots \\quad x_{sl})^T \\in \\mathbb{R}^{k+l}.$$\n",
    "\n",
    "Implement the function `get_lr_prediction` that performs the following steps:\n",
    "\n",
    "1. Construct the feature vector for each row of the train set `df_train_formatted`, using the above formula.\n",
    "1. Use an Sklearn `StandardScaler` (with default parameters) to fit and transform the train set `df_train_formatted`.\n",
    "1. Train an Sklearn `LogisticRegression` model on the train set `df_train_formatted`.\n",
    "1. Use this model to perform prediction on the test set `df_test_formatted`.\n",
    "1. Return the trained LR model and its accuracy on the test set (i.e., the number of correct predictions divided by the test set size).\n",
    "\n",
    "**Notes**:\n",
    "* When creating a `LogisticRegression` model you should set `random_state` to the input `seed` and `max_iters` to 1000. You do not need to specify any other parameter.\n",
    "* Make sure you also standardize the feature matrix built from the test set before inputting it to the LR model for prediction.\n",
    "* Be careful when dealing with nested NumPy arrays. If you get a NumPy array that contains other NumPy arrays, you can use `np.stack` to turn it to a normal multi-dimensional array (otherwise it will be treated as a 1D array of pointers to other arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_prediction(df_train_formatted, df_test_formatted, question_embeddings_map, context_embeddings_map, seed = 0):\n",
    "    \"\"\"\n",
    "    Train and evaluate the performance of a binary logisitic regression model to predict\n",
    "    whether a context sentence contains the answer to a given question.\n",
    "    \n",
    "    args:\n",
    "        df_train_formatted (pd.DataFrame) : the train set dataframe with 3 columns:\n",
    "            question, context_sentence, is_answer_sent\n",
    "        df_test_formatted (pd.DataFrame) : the test set dataframe with 3 columns:\n",
    "            question, context_sentence, is_answer_sent\n",
    "        question_embeddings_map (dict[str, np.ndarray]) : a mapping from question to word embedding\n",
    "        context_embeddings_map (dict[str, np.ndarray]) : a mapping from context sentence to word embedding\n",
    "        seed (int) : the random generator used in LogisticRegression\n",
    "        \n",
    "    return: Tuple(trained_model, accuracy)\n",
    "        trained_model (sklearn.linear_model.LogisticRegression) : the LR model trained on the train set\n",
    "        accuracy (float) : the accuracy score of the trained model on the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    df_train_formatted[\"vec\"]=df_train_formatted.apply(lambda x: np.hstack((question_embeddings_map[x[\"question\"]],context_embeddings_map[x[\"context_sentence\"]])))\n",
    "    X=df_train_formatted.vec.values\n",
    "    y=df_train_formatted.is_answer_sent.values\n",
    "    sc = StandardScaler()\n",
    "    sc = sc.fit(X)\n",
    "    X = sc.transform(X)\n",
    "\n",
    "    lr=LogisticRegression(random_state=seed, max_inters=1000)\n",
    "    \n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    df_test_formatted[\"vec\"]=df_test_formatted.apply(lambda x: np.hstack((question_embeddings_map[x[\"question\"]],context_embeddings_map[x[\"context_sentence\"]])))\n",
    "    X_test=df_test_formatted.vec.values\n",
    "    X_test = sc.transform(X)\n",
    "    y_test_pre=lr.predict(X_test)\n",
    "    y_test=df_test_formatted.is_answer_sent.values\n",
    "    acc=np.sum(y_test_pre==y_test)/len(y_test)\n",
    "                                                       \n",
    "                                        \n",
    "    return lr,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_get_lr_prediction():\n",
    "    \"Test on the first 1000 rows of the dataset\"\n",
    "    df_squad_train_mini, df_squad_test_mini = train_test_split(df_squad.head(1000), train_size = 0.8, random_state = 0)\n",
    "    df_train_formatted_mini = build_data_for_classification(df_squad_train_mini.reset_index())\n",
    "    df_test_formatted_mini = build_data_for_classification(df_squad_test_mini.reset_index())\n",
    "    lr_mini, acc_mini = get_lr_prediction(\n",
    "        df_train_formatted_mini, df_test_formatted_mini,\n",
    "        question_embeddings_map, context_embeddings_map\n",
    "    )\n",
    "    assert lr_mini.coef_.flatten()[:10].round(2).tolist() == [\n",
    "        0.07, -0.01, -0.03, -0.03, -0.01, 0.01, -0.03, 0.0, 0.04, -0.04\n",
    "    ]\n",
    "    assert lr_mini.intercept_.round(2)[0] == -2.73\n",
    "    assert round(acc_mini, 2) ==  0.81\n",
    "    \n",
    "    \"\"\"Test on the entire dataset\"\"\"\n",
    "    lr, acc = get_lr_prediction(df_train_formatted, df_test_formatted, question_embeddings_map, context_embeddings_map)\n",
    "    assert lr.coef_.flatten()[:10].round(2).tolist() == [\n",
    "        -0.04, 0.0, 0.01, 0.0, -0.0, 0.0, -0.01, -0.0, -0.03, 0.01\n",
    "    ]\n",
    "    assert lr.intercept_.round(2)[0] == -1.54\n",
    "    assert round(acc, 2) == 0.80\n",
    "    \n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_get_lr_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain about 80% accuracy in this binary classification task, which is not too bad! However, it's important to note that this accuracy cannot be compared with those from previous questions, because it is evaluated in a different setting (`df_test_formatted`). If we were only interested in whether the ground truth answer sentences are correctly detected, we would evaluate the accuracy on the original test set `df_squad_test`, instead of the formatted one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While logistic regression on Sent2vec representation performs relatively well, it still relies on a *uni-directional* representation of words. In this setting, the same word is always mapped to the same vector, even though it may have different meanings in different contexts (e.g., the word `bank` in `bank account` is not the same as in `river bank`). The final model we will explore in this project, which also addresses the above issue, is called BERT (Bi-directional Encoder Representations from Transformers). This is a language model that learns to predict the probability of a sequence of words. The reason for BERT's success is its large feedforward layers and its attention heads, giving it 110 million parameters for the base model and 340 million parameters for the large model. It has been trained on Wikipedia articles and the Book Corpus dataset, which contains text from over 10,000 books of different genres over the tasks of next sentence prediction (NSP) and masked language modeling (MLM). BERT represents the current state of the art in various NLP task, including question answering.\n",
    "\n",
    "One nice feature of NLP models like BERT is that they have already been pre-trained on massive text corpuses, but can also be fine-tuned further for a specific domain (in this case, our SQuAD dataset). We will implement this workflow in the rest of the project. First, we define a sub-class of `Dataset`, similar to Project 6, to turn our SQuaD dataset into a format that PyTorch can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQuADDataset(Dataset):\n",
    "    def __init__(self, df_squad):\n",
    "        \"\"\"\n",
    "        Class constructor.\n",
    "        \"\"\"\n",
    "        self.data = df_squad\n",
    "        self.data_cols = [\"question\", \"context_paragraph\", \"answer_start\", \"answer_end\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the dataset length.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get the question, context paragraph, answer start and answer end value\n",
    "        at the row specified by the input index from the dataset.\n",
    "        \"\"\"\n",
    "        return tuple(self.data.loc[index, self.data_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Tokenization for BERT\n",
    "Similar to how our `LogisticRegression` model expects a real-valued vector as input, Bert also has its own way of constructing the input. At a high level, we want to convert each input tuple\n",
    "```\n",
    "(question, context_paragraph, answer_start, answer_end)\n",
    "```\n",
    "into a tuple\n",
    "```\n",
    "(encoding, token_start, token_end)\n",
    "```\n",
    "where `encoding` is a dictionary that maps three keywords -- `\"input_ids\"`, `\"token_type_ids\"`, `\"attention_mask\"` -- to their respective vector representations.\n",
    "\n",
    "Implement the class `SQuADTokenizer` that performs the above conversion using a pre-trained Bert tokenizer. In particular, the class constructor accepts a `BertTokenizer` instance and the maximum sequence size `max_length`, which are stored as instance variables. Then, the `__call__` function acccepts a batch of data and performs the following steps:\n",
    "1. Extract the questions, context paragraphs, answer start indexes, and answer end indexes from the batch.\n",
    "1. Input the questions and contexts to the tokenizer as separate lists, so that the tokenizer can append special tokens such as `[SEP]` that help BERT recognize different passages. You should also set the following parameters: `padding` to `\"longest\"`, `truncation` to `True`, `max_length` to the stored `max_len`, and `return_tensors` to `\"pt\"`.\n",
    "1. Convert the `answer_start` and `answer_end` character indices to the indices of the two tokens that correspond to these start and end characters. For example, let's say:\n",
    "```py\n",
    "question = \"Which pets does your son have?\"\n",
    "context_paragraph = \"My son loves pets. He has two cats and a dog.\"\n",
    "tokenized_context = [\"my\", \"son\", \"love\", \"pet\", \"he\", \"have\", \"two\", \"cat\", \"and\", \"a\", \"dog\"]\n",
    "answer_start, answer_end = 26, 44 # answer = \"two cats and a dog\"\n",
    "```\n",
    "now you need to identify the token that corresponds to the character `context_paragraph[answer_start]`. This character is `t` and the corresponding token is `two`, which is at index `6` in `tokenized_context`. Similarly for `answer_end`, the character `context_paragraph[answer_end]` is `g`, and the corresponding token is `dog`, which is at index 10 in `tokenized_context`. In summary, you are converting\n",
    "```\n",
    "(answer_start = 26, answer_end = 44)\n",
    "```\n",
    "to\n",
    "```\n",
    "(token_start = 6, token_end = 10)\n",
    "```\n",
    "1. Return the encoded data (output from calling the tokenizer on the input questions and context paragraphs in Step 2), as well as the list of token start indexes and the list of token end indexes.\n",
    "\n",
    "**Notes**:\n",
    "* The [Tokenizer page](https://huggingface.co/transformers/main_classes/tokenizer.html) and the section about [using the tokenizer](https://huggingface.co/transformers/quicktour.html?highlight=max_length) on HuggingFace may be helpful.\n",
    "* To convert `(answer_start, answer_end)` to `(token_start, token_end)`, you can use the [.char_to_token](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.BatchEncoding.char_to_token) method. Here the `batch_or_char_index` is the index of the current data point within the input batch, and `sequence_index` should be 1 because we are doing this conversion on the context paragraph, which is the second input string to the tokenizer.\n",
    "* Sometimes calling `.char_to_token` will return `None` because the tokens have been changed (e.g., due to lemmatization) from their original form in `context_paragraph`. A simple work-around is to also consider the token that corresponds to the next or previous character. If doing so still yields `None`, we will just set the token index as `max_len` as a last resort. More formally, you should assign `token_start` to the first element that is not `None` among the following four values:\n",
    "    * `char_to_token(char_index = answer_start, ...)`\n",
    "    * `char_to_token(char_index = answer_start+1, ...)`\n",
    "    * `char_to_token(char_index = answer_start-1, ...)`\n",
    "    * `max_len`\n",
    "```\n",
    "and do a similar assignment for `token_end`.\n",
    "* When extracting `answer_starts` and `anwer_ends` from the batch, they will have the type `torch.Tensor` (i.e., these are float tensors). You should convert them to `LongTensor` so that they can be used in `char_to_token()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_idx(encoding,start,max_l):\n",
    "    temp=encoding.char_to_token( batch_or_char_index=start, sequence_index=1)\n",
    "    if temp !=None:\n",
    "        return temp\n",
    "    \n",
    "    temp=encoding.char_to_token( batch_or_char_index=start+1, sequence_index=1)\n",
    "    if temp!=None:\n",
    "        return temp\n",
    "    temp=encoding.char_to_token( batch_or_char_index=start-1, sequence_index=1)\n",
    "    if temp!=None:\n",
    "        return temp\n",
    "    else:\n",
    "        return max_l\n",
    "\n",
    "class SQuADTokenizer:\n",
    "    def __init__(self, tokenizer, max_len = 512):\n",
    "        \"\"\"\n",
    "        Store the input BertTokenizer instance and the max length\n",
    "        \"\"\"\n",
    "        self.tk=tokenizer\n",
    "        self.max_l= max_len\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        Perform tokenization on a batch of data\n",
    "        \n",
    "        args:\n",
    "            batch (Tuple[questions, contexts, answer_starts, answer_ends]):\n",
    "                questions (List[str]) : a list of questions\n",
    "                contexts (List[str]) : a list of context paragraphs\n",
    "                answer_starts (List[int]) : a list of answer start indexes\n",
    "                answer_ends (List[int]) : a list of answer end indexes\n",
    "        \n",
    "        returns:\n",
    "            Tuple[encoding, token_starts, token_ends]\n",
    "                encoding (dict[str, tensor]): the output of calling tokenizer on the questions and contexts\n",
    "                token_starts (List[int]) : the list of indexes for the tokens that correspond to the first answer character\n",
    "        \"\"\"\n",
    "        \n",
    "        question,context,start,end=batch\n",
    "     \n",
    "        encoding=self.tk(question,context,padding=\"longest\", truncation=True, max_length=self.max_l, return_tensors =\"pt\")\n",
    "      \n",
    "        start=pd.DataFrame({\"temp\":start})\n",
    "        end=pd.DataFrame({\"temp\":end})\n",
    "        \n",
    "        \n",
    "        out_start=start.temp.apply(lambda x:get_token_idx(encoding,x,self.max_l)).values \n",
    "        out_end=end.temp.apply(lambda x:get_token_idx(encoding,x,self.max_l)).values \n",
    "\n",
    "        return encoding,list(out_start),list(out_end)\n",
    "        \n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 20773]\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_tokenizer():\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    batch_tokenizer = SQuADTokenizer(tokenizer)\n",
    "    example_1 = (\n",
    "        ['When did Beyonce start becoming popular?'],\n",
    "        ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'],\n",
    "        [269],\n",
    "        [286]\n",
    "    )\n",
    "    encoding, token_starts, token_ends = batch_tokenizer(example_1)\n",
    "    check_equal(list(encoding[\"input_ids\"].shape), [1, 174])\n",
    "   \n",
    "    check_equal(encoding[\"input_ids\"][0][:10].numpy().tolist(), [\n",
    "        101, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 20773\n",
    "    ])\n",
    "    check_equal(encoding[\"token_type_ids\"].numpy().tolist(), [[0]*9 + [1]*165])\n",
    "    check_equal(encoding[\"attention_mask\"].numpy().tolist(), [[1] * 174])\n",
    "    check_equal(token_starts, [75])\n",
    "    check_equal(token_ends, [79])\n",
    "\n",
    "    example_2 = (\n",
    "        ['When did Beyonce start becoming popular?', 'What score did the writer from the Chicago Tribune give to Spectre?'], \n",
    "        ['Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'Critical appraisal of the film was mixed in the United States. In a lukewarm review for RogerEbert.com, Matt Zoller Seitz gave the film 2.5 stars out of 4, describing Spectre as inconsistent and unable to capitalise on its potential. Kenneth Turan, reviewing the film for Los Angeles Times, concluded that Spectre \"comes off as exhausted and uninspired\". Manohla Dargis of The New York Times panned the film as having \"nothing surprising\" and sacrificing its originality for the sake of box office returns. Forbes\\' Scott Mendelson also heavily criticised the film, denouncing Spectre as \"the worst 007 movie in 30 years\". Darren Franich of Entertainment Weekly viewed Spectre as \"an overreaction to our current blockbuster moment\", aspiring \"to be a serialized sequel\" and proving \"itself as a Saga\". While noting that \"[n]othing that happens in Spectre holds up to even minor logical scrutiny\", he had \"come not to bury Spectre, but to weirdly praise it. Because the final act of the movie is so strange, so willfully obtuse, that it deserves extra attention.\" In a positive review Rolling Stone, Peter Travers gave the film 3.5 stars out of 4, describing \"The 24th movie about the British MI6 agent with a license to kill is party time for Bond fans, a fierce, funny, gorgeously produced valentine to the longest-running franchise in movies\". Other positive reviews from Mick LaSalle from the San Francisco Chronicle, gave it a perfect 100 score, stating: “One of the great satisfactions of Spectre is that, in addition to all the stirring action, and all the timely references to a secret organization out to steal everyone’s personal information, we get to believe in Bond as a person.” Stephen Whitty from the New York Daily News, gave it an 80 grade, saying: “Craig is cruelly efficient. Dave Bautista makes a good, Oddjob-like assassin. And while Lea Seydoux doesn’t leave a huge impression as this film’s “Bond girl,” perhaps it’s because we’ve already met — far too briefly — the hypnotic Monica Bellucci, as the first real “Bond woman” since Diana Rigg.” Richard Roeper from the Chicago Sun-Times, gave it a 75 grade. He stated: “This is the 24th Bond film and it ranks solidly in the middle of the all-time rankings, which means it’s still a slick, beautifully photographed, action-packed, international thriller with a number of wonderfully, ludicrously entertaining set pieces, a sprinkling of dry wit, myriad gorgeous women and a classic psycho-villain who is clearly out of his mind but seems to like it that way.” Michael Phillips over at the Chicago Tribune, gave it a 75 grade. He stated: “For all its workmanlike devotion to out-of-control helicopters, “Spectre” works best when everyone’s on the ground, doing his or her job, driving expensive fast cars heedlessly, detonating the occasional wisecrack, enjoying themselves and their beautiful clothes.” Guy Lodge from Variety, gave it a 70 score, stating: “What’s missing is the unexpected emotional urgency of “Skyfall,” as the film sustains its predecessor’s nostalgia kick with a less sentimental bent.”'], \n",
    "        [269, 2118], \n",
    "        [286, 2120]\n",
    "    )\n",
    "    encoding, token_starts, token_ends = batch_tokenizer(example_2)\n",
    "    check_equal(list(encoding[\"input_ids\"].shape), [2, 512])\n",
    "    check_equal(encoding[\"input_ids\"][0][-10:].numpy().tolist(), [0]*10)\n",
    "    check_equal(encoding[\"token_type_ids\"].numpy().tolist()[0], [0]*9 + [1]*165 + [0]*338)\n",
    "    check_equal(encoding[\"token_type_ids\"].numpy().tolist()[1], [0]*16 + [1]*496)\n",
    "    check_equal(encoding[\"attention_mask\"][0].numpy().tolist(), [1]*174 + [0]*338)\n",
    "    check_equal(token_starts, [75, 512])\n",
    "    check_equal(token_ends, [79, 512])\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Fine-tuning BERT\n",
    "With the tokenizer ready, we can begin fine-tuning a pre-trained BERT model to our dataset with the following steps:\n",
    "1. Move the input `model` to `device` and set it to training mode.\n",
    "1. Repeat `n_iters` times:\n",
    "    * For every batch of data from the dataloader:\n",
    "        * Use the input `tokenizer` (an instance of the class `SQuADTokenizer` that you implemented) to encode this batch, yielding the tuple `(encoding, token_starts, token_ends)`.\n",
    "        * Extract the `input_ids`, `token_type_ids` and `attention_mask` from `encoding`. Convert these tensors to `LongTensor` and move them to `device`.\n",
    "        * Perform the usual PyTorch training workflow (zero grad, forward pass, backprop, ...). See the PyTorch primer for a reminder.\n",
    "        \n",
    "Implement the function `fine_tune_bert` that, given a pretrained BERT model and other training parameters, performs the above training procedure. This function should return the fine-tuned model and the average training loss across epochs.\n",
    "\n",
    "**Notes**:\n",
    "* Consult the [Bert documentation page](https://huggingface.co/transformers/v4.7.0/model_doc/bert.html#transformers.BertForQuestionAnswering.forward) for which parameters to specify in the forward pass.\n",
    "* To carry out the forward pass, you can input the encoding elements (after convering them to datatype Long), along with `token_starts` and `token_ends`, to `model`. Calling `.loss` on the output of the forward pass will yield the loss value.\n",
    "* We also provide a `verbose` flag. If you would like to add print debugging messages during model training, simply precede each print statement with an `if verbose` check, for example:\n",
    "```py\n",
    "if verbose:\n",
    "    print(\"Training loss\", train_loss)\n",
    "```\n",
    "The autograder will only call your function with `verbose = False`, so that your printout messages do not interfere with grading.\n",
    "* To compute the average training loss, you should sum all the losses from every forward pass, then divide this sum by the number of epochs at the end of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_bert(model, n_epochs, optimizer, dataloader, squad_tokenizer, device, verbose = False):\n",
    "    \"\"\"\n",
    "    Fine-tune a pre-trained BERT model on the SQuAD dataset.\n",
    "    \n",
    "    args:\n",
    "        model (BertForQuestionAnswering) : a pre-trained BERT model for QA tasks\n",
    "        n_epochs (int) : the number of epochs to train\n",
    "        dataloader (DataLoader) : a data loader that provides access to one batch of data at a time\n",
    "        squad_tokenizer (SQuADTokenizer) : a tokenizer instance to be called on every batch of data from dataloader\n",
    "        device (torch.device) : the device (CPU or Cuda) that the model and data should be moved to\n",
    "        verbose (bool) : a flag that indicates whether debug messages should be printed out\n",
    "    \n",
    "    return:\n",
    "        model (BertForQuestionAnswering) : the fine-tuned model\n",
    "        avg_loss (float) : the average training loss across epochs\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_fine_tune_bert():\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    squad_tokenizer = SQuADTokenizer(tokenizer)\n",
    "    \n",
    "    \"\"\"Train on 8 data points\"\"\"\n",
    "    train_dataset = SQuADDataset(df_squad.head(8)[[\"question\", \"context_paragraph\", \"answer_start\", \"answer_end\"]])\n",
    "    squad_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=6, worker_init_fn=_init_fn)\n",
    "    model = BertForQuestionAnswering.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)  \n",
    "    model, avg_train_loss = fine_tune_bert(model, 1, optimizer, squad_dataloader, squad_tokenizer, device)\n",
    "    assert avg_train_loss < 5.0, avg_train_loss\n",
    "    \n",
    "    \"\"\"Train on 100 data points\"\"\"\n",
    "    train_dataset = SQuADDataset(df_squad.head(100)[[\"question\", \"context_paragraph\", \"answer_start\", \"answer_end\"]])\n",
    "    squad_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=6, worker_init_fn=_init_fn)\n",
    "    model = BertForQuestionAnswering.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)  \n",
    "    model, avg_train_loss = fine_tune_bert(model, 1, optimizer, squad_dataloader, squad_tokenizer, device)\n",
    "    assert avg_train_loss < 38, avg_train_loss\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "%time test_fine_tune_bert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fine-tune the model on 80% of the data (the remaining 20% will be for evaluation). Because this takes a long time, we will only do it for 1 epoch.\n",
    "\n",
    "**Notes**:\n",
    "* The following cell will take about **2 hours** to run, and is **required** for the next question. We recommend that you make a submission to TPZ at this point, to make sure you have everything correct so far. Ideally you would want to avoid having to fine-tune Bert more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "train_indexes, test_indexes = train_test_split(df_squad.index, train_size = 0.8, random_state = 0)\n",
    "df_squad_train = df_squad.loc[train_indexes, [\"question\", \"context_paragraph\", \"answer_start\", \"answer_end\"]].reset_index()\n",
    "df_squad_test = df_squad.loc[test_indexes].reset_index()\n",
    "\n",
    "train_dataset = SQuADDataset(df_squad_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=False, num_workers=6, worker_init_fn=_init_fn, pin_memory = True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "squad_tokenizer = SQuADTokenizer(tokenizer)\n",
    "\n",
    "%time tuned_model, avg_train_loss = fine_tune_bert(model, 1, optimizer, train_dataloader, squad_tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also save the fine-tuned model into a directory to reuse it later. Note that the following code will create a directory `bert_fine_tuned_squad` with several files in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "tuned_model.cpu().save_pretrained(\"bert_fine_tuned_squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the fine tuned model performs. We provide the following function `get_bert_prediction` to predict the answer given a pair of question and context. Overall the inference process is very similar to the forward pass during fine-tuning, except that we don't provide the starting and ending tokens to the Bert model, since those are what we need to predict.\n",
    "\n",
    "You may also notice that we are looping through each data point, instead of doing inference in a vectorized manner. The reason is that this same inference code will be used for model deployment on CPU later, where we have limited memory and cannot afford to process data in batches (recall how you performed inference both in the loop approach and the batch approach in the OPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_prediction(questions, contexts, device, model=None, tokenizer=None):\n",
    "    '''\n",
    "    Given list of questions and list of corresponding contexts predicts answers using BERT.\n",
    "\n",
    "    args:\n",
    "        questions (List[string]): list of questions to be answered\n",
    "        contexts (List[string]): list of context paragraphs, each for answering a question in the input questions\n",
    "        device (torch.device) : the device (CPU or Cuda) that the model and data should be moved to\n",
    "        model (BertForQuestionAnswering): BERT model to be used for question answering \n",
    "            or None - if None, `bertserini-bert-base-squad` will be loaded\n",
    "        tokenizer (BertTokenizerFast object): tokenizer to be used for encoding questions and contexts\n",
    "            or None - if None, `bertserini-bert-base-squad` will be loaded\n",
    "    return:\n",
    "        outputs (List[string]): list of generated answers\n",
    "    '''\n",
    "    \n",
    "    if model is None:\n",
    "        model = BertForQuestionAnswering.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    if tokenizer is None:\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    for question, context in tqdm(zip(questions, contexts), total=len(questions)):\n",
    "\n",
    "        encoded_seq = tokenizer(question, context, padding=\"longest\", truncation=True, max_length=512)\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoded_seq[\"input_ids\"])\n",
    "        \n",
    "        input_ids = torch.LongTensor([encoded_seq[\"input_ids\"]]).to(device)\n",
    "        token_type_ids = torch.LongTensor([encoded_seq[\"token_type_ids\"]]).to(device)\n",
    "        attention_mask = torch.FloatTensor([encoded_seq[\"attention_mask\"]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, \n",
    "                           attention_mask=attention_mask, \n",
    "                           token_type_ids=token_type_ids)\n",
    "        logits_start, logits_end = output['start_logits'], output['end_logits']\n",
    "        token_start = torch.argmax(logits_start)\n",
    "        token_end = torch.argmax(logits_end)\n",
    "        \n",
    "        outputs.append(tokenizer.convert_tokens_to_string(tokens[token_start:token_end]))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try predicting one row of data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"question:\\n{}\\ncontext:\\n{}\\nanswer:\\n{}\\n\".format(\n",
    "    df_squad.loc[200, \"question\"],\n",
    "    df_squad.loc[200, \"context_paragraph\"],\n",
    "    df_squad.loc[200, \"answer\"]\n",
    "))\n",
    "\n",
    "print(\"Bert prediction:\", get_bert_prediction(\n",
    "    df_squad.loc[[200], \"question\"],\n",
    "    df_squad.loc[[200], \"context_paragraph\"],\n",
    "    device,\n",
    "    model = tuned_model\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it does work! Now let's see how accurate the fine tuned model is on the entire test set. We'll also compute the accuracy of a pre-trained model without fine-tuning, to see how much improvement our fine-tuning provided. Each of the following two cells will take about **11 minutes** to run, and they are **not** required for later questions, so feel free to skip them for now and revisit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "pretrained_test_prediction = get_bert_prediction(\n",
    "    df_squad_test[\"question\"], df_squad_test[\"context_paragraph\"],\n",
    "    device, BertForQuestionAnswering.from_pretrained('rsvp-ai/bertserini-bert-base-squad')\n",
    ")\n",
    "print( (np.array(pretrained_test_prediction) == df_squad_test[\"answer\"].str.lower().values ).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "tuned_test_predictions = get_bert_prediction(\n",
    "    df_squad_test[\"question\"], df_squad_test[\"context_paragraph\"],\n",
    "    device, tuned_model\n",
    ")\n",
    "print( (np.array(tuned_test_predictions) == df_squad_test[\"answer\"].str.lower().values ).mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the pretrained model did not work well at all, while fine-tuning the model for one epoch already yields a large improvement in accuracy (about 58%) on the test set. Naturally, the model still has plenty of room for improvement when trained for more epochs, but doing so requires a lot more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Deployment\n",
    "As seen from this project, building a QA system involves a very complex technology stack. To make your model easily accessible to others, you can deploy it to a public endpoint on Azure, using the same workflow from Project 6. We have built several models so far and they can all be deployed together under the same endpoint. However, for the rest of this project, let's focus on Bert deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.webservice import LocalWebservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will provide a brief reminder of the involved steps. You can consult the code from your Project 6 or the [model deployment primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/p5-machine-learning-azure-primer/azure_model_deployment_primer.ipynb) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Initialize workspace with `Workspace.from_config()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Register the model with `Model.register()`**\n",
    "\n",
    "The `model_path` parameter should be set to the name of your Bert model directory, `\"./bert_fine_tuned_squad\"`. The `model_name` parameter should be set to `\"bert_fine_tuned\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Create scoring script and API endpoint**\n",
    "\n",
    "Our grader will send a POST request to your endpoint, where the JSON content is structured as follows:\n",
    "\n",
    "```py\n",
    "{\n",
    "    \"questions\" : [\n",
    "        \"How many parameters does BERT-large have?\",\n",
    "        \"When did Beyonce start becoming popular?\"\n",
    "    ],\n",
    "\n",
    "    \"context_paragraphs\" : [\n",
    "        \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\",\n",
    "        'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n",
    "    ]\n",
    "}\n",
    "```\n",
    "Here `questions` is a list of `N` questions and `context_paragraphs` is a list of `N` context paragraphs. For each pair of question and context paragraph, you should tokenize and input them to the fine-tuned Bert model, and return a JSON with the following format:\n",
    "```py\n",
    "{\n",
    "    'predicted_ans' : ['340', 'late 1990s']\n",
    "}\n",
    "```\n",
    "where the key `predicted_ans` maps to a list of `N` strings, with each string being the predicted answer for one input pair of question and context paragraph.\n",
    "\n",
    "Implement the `init` and `run` function in the `score.py` file to perform the above processing. In particular,\n",
    "* `init` will load the fine-tuned Bert model from file and store it in a global variable.\n",
    "* `run` will convert the input `input_data` to JSON, extract the questions and contexts, then perform inference and return the specified JSOn response. You can reuse the code from `get_bert_predictions` that we provided earlier.\n",
    "\n",
    "**Notes**:\n",
    "* To load the fine tuned Bert model, you can call\n",
    "```py\n",
    "BertForQuestionAnswering.from_pretrained(Model.get_model_path(\"bert_fine_tuned\"))\n",
    "```\n",
    "Also remember that to modify a global variable, you need to use the `global` keyword.\n",
    "* When doing inference you can use the pre-trained tokenizer `\"rsvp-ai/bertserini-bert-base-squad\"`. This tokenizer can also be initialized in `init` so that you don't need to take time loading it during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import os, json, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForQuestionAnswering\n",
    "from azureml.core.model import Model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    Load the fine-tuned Bert model from file and store it in a global variable.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def run(input_data):\n",
    "    \"\"\"\n",
    "    Convert the input data from string to JSON, extract the questions and contexts,\n",
    "    then perform inference with Bert and return the specified JSOn response \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that the content of `score.py` is as you expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "!cat score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Create environment file**\n",
    "\n",
    "Now you will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by Azure ML. The `pip_packages` parameter value should be the following list:\n",
    "```py\n",
    "['azureml-defaults', 'torch==1.9.0', 'transformers==4.7.0', 'numpy']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Deploy to local service**\n",
    "\n",
    "Follow the steps in the [model deloyment primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/machine-learning-azure-primer/azure_model_deployment_primer.ipynb) to create an `Environment`, an `InferenceConfig`, a `LocalWebservice`, a `Model.deploy` object, and call `wait_for_deployment` on it. This code may take about 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Test the local service**\n",
    "\n",
    "You should change the `local_service` variable below to the variable name that you used earlier to store the return value of `Model.deploy`. Check that the response JSON matches the format specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "input_json = json.dumps({\n",
    "    \"questions\" : [\n",
    "        \"How many parameters does BERT-large have?\",\n",
    "        \"When did Beyonce start becoming popular?\"\n",
    "    ],\n",
    "\n",
    "    \"context_paragraphs\" : [\n",
    "        \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\",\n",
    "        'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n",
    "    ]\n",
    "})\n",
    "\n",
    "input_json = bytes(input_json, encoding = \"utf8\")\n",
    "output = local_service.run(input_json)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your model may output `340` or `340m` as the answer for the first question -- both are acceptable, due to the random weights in the Bert model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Deploy to ACI container**\n",
    "\n",
    "Now that your local service has worked properly, the last step is to deploy it to a pulic endpoint. Follow the steps in the primer to create an `AciWebService` and a new `Model.deploy` object, then call `wait_for_deployment` on it. This code should take at most 10 minutes to run. If it takes longer, you should consult the \"Monitoring public deployment\" section in the primer to diagnose the issues.\n",
    "\n",
    "**Notes**:\n",
    "* When creating the `AciWebService`, you can specify `cpu_cores = 3.8` and `memory_gb = 15` to maximize processing power in the deployment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Test the public service**\n",
    "\n",
    "Let's use the same input json from earlier and check that the public endpoint is working as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "deployed_uri = aci_service.scoring_uri\n",
    "print(deployed_uri)\n",
    "\n",
    "input_json = json.dumps({\n",
    "    \"questions\" : [\n",
    "        \"How many parameters does BERT-large have?\",\n",
    "        \"When did Beyonce start becoming popular?\"\n",
    "    ],\n",
    "\n",
    "    \"context_paragraphs\" : [\n",
    "        \"BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance.\",\n",
    "        'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'\n",
    "    ]\n",
    "})\n",
    "\n",
    "response = requests.post(deployed_uri, input_json, headers = {'Content-Type' : 'application/json'})\n",
    "print(response.status_code)\n",
    "print(json.loads(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Deploying Bert model\n",
    "We provide a local test to check that your deployed model can handle a request that contains 100 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_deploy_bert():\n",
    "    df_test_deploy = df_squad.sample(100, random_state = 100)\n",
    "    input_json = json.dumps({\n",
    "        \"questions\" : df_test_deploy[\"question\"].tolist(),\n",
    "        \"context_paragraphs\" : df_test_deploy[\"context_paragraph\"].tolist()\n",
    "    })\n",
    "    response = requests.post(deployed_uri, input_json, headers = {'Content-Type' : 'application/json'})\n",
    "    check_equal(response.status_code, 200)\n",
    "    \n",
    "    predicted_ans = np.array(json.loads(response.content)[\"predicted_ans\"])\n",
    "    ans = df_test_deploy[\"answer\"].str.lower().values\n",
    "    accuracy = (predicted_ans == ans).mean()\n",
    "    assert accuracy >= 0.3, accuracy\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_deploy_bert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's write the deployed URI to a text file so that it can be submitted to the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "with open('scoring_uri.txt', 'w') as f:\n",
    "    f.write(deployed_uri)\n",
    "    print(\"Saved scoring_uri to file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 9: Clean up cloud resources**\n",
    "\n",
    "You have completed all the questions in this project! One last step you need to do is to make sure you clean up your resources properly, so that no unexpected charge is incurred. **You will still need to use Azure for the final exam**.\n",
    "\n",
    "Use the left navigation bar in the Azure Machine Learning Studio to manage your computes and endpoints. If you don't anticipate any further usage of Azure ML Studio for this project, you should go back to the [Azure homepage](https://portal.azure.com/) and delete the entire resource group, as the resource group itself also incurs charges over time, even without any computes or endpoints.\n",
    "\n",
    "<p style=\"color:red;\">\n",
    "    <strong>To check your remaining budget, you need to visit the <a href=\"https://portal.azure.com/#blade/Microsoft_Azure_Education/EducationMenuBlade/overview\">Education</a> tab on Azure. The Cost Mangement + Billing Tab will not display anything.</strong>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
